{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1803a9a7",
   "metadata": {},
   "source": [
    "# Cel zadania i problem biznesowy\n",
    "\n",
    "\n",
    "# Preprocessing\n",
    "\n",
    "Nasz zbiór danych w postaci .csv zawierał aż 33 kolumny, co wiązało się z faktem że nasz preprocessing był dość obszerny. Do każdej kolumny staraliśmy się podejść indywidualnie i odpowiednio przetransformować jej wartości, aby póżniej algorytm uczenia maszynowego działał poprawnie. \n",
    "\n",
    "W przypadku kolumn kategorycznych zazwyczaj decydowaliśmy się na użycie algorytmu OneHotEncoding z pakietu scikit-learn. Jest to dość intuicyjna metoda, dzięki której nie tracimy żadnych informacji. Dodaje on do zbioru danych dodatkowe kolumny (ich liczność jest odpowiednia liczbą kategorii), a następnie daje wartość 1 tam, gdzie jest odpowiednia kategoria. Sprawia to, że informacje te są zakodowane w postaci liczbowej. Niestety sprawia to, że dodajemy wiele dodatkowych kolumn, co negatywnie wpływa na interpretowalność modelu zbudowanego na tej podstawie. Przykładowymi kolumnami kategorycznymi, na których zastosowaliśmy ten algorytm to: 'TopThreeAmericanName', 'WheelTypeID','Nationality', itd... \n",
    "\n",
    "Kolejnym ważnym etapem preprocessingu było zastosowanie normalizacji danych. Zważając na fakt, że budowaliśmy modele które są czułe na skale zmiennych (np. SVM) musieliśmy wszystkie wartości liczbowe w jakiś sposób przeskalować, aby były między sobą 'porównywalne'. Zastosowaliśmy funkcję StandardScaler, która odejmuje od każdej wartości średnią arytmetyczną (mean), a następnie dzieli przez wariancję. Przykładowymi kolumnami objętymi tym algorytmem są: 'VehOdo','VehBCost', 'WarrantyCost', itd ... \n",
    "\n",
    "\n",
    "\n",
    "Tutaj jeszcze bardzo warto wspomnieć o tym wheelID ze sie daje to dużo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fa50c5",
   "metadata": {},
   "source": [
    "# Modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3632ef",
   "metadata": {},
   "source": [
    "## Dummy classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8128136",
   "metadata": {},
   "source": [
    "Aby sprawdzić, czy nasze dane są dobrze przygotowane do trenowania modelów wytrenowaliśmy *dummy classifier*, który przyporządkowuje po prostu jedną z dwóch kategorii do obserwacji."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d28dff",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "187ea4cb",
   "metadata": {},
   "source": [
    "## KNN classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56df16",
   "metadata": {},
   "source": [
    "moze tutaj opisac troche jak działa ten model ale nie wiem czy to konieczne"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3460eb8",
   "metadata": {},
   "source": [
    "Po wykonaniu hiperparametryzacji za pomocą metody grid search sprawdziliśmy jak sprawuje się model na zbiorze walidacyjnym"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e09b19",
   "metadata": {},
   "source": [
    "![roc curve](plots/KNN_roc.png)\n",
    "\n",
    "Krzywa ROC - jak widać model nie sprawuje się zbyt dobrze. Otrzymana wartość gini dla zbioru walidacyjnego to zaledwie 0.3332"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46cd47a",
   "metadata": {},
   "source": [
    "Model KNN sprawuje się gorzej przy bardzo wielu wymiarach. W związku z tym postanowiliśmy zredukować liczbę wymiarów. Z pomocą przyszedł nam algorytm PCA, który zastosowaliśmy.\n",
    "\n",
    "\n",
    "Aby zachować dostatecznie dużo informacji postanowliśmy wybrać liczbę wymiarów PCA, tak aby łączna wariancja miała wartość co najmniej 95%.\n",
    "\n",
    "![pca](plots/PCA_variance.png)\n",
    "\n",
    "\n",
    "Okazało się jednak, że zastosowana redukcja wymiarów nie przyniosła satysfakcjonujących rezultatów, gdyż model po redukcji wymiarów sprawował się gorzej.\n",
    "\n",
    "![roc curve](plots/KNN_pca_roc.png)\n",
    "\n",
    "\n",
    "\n",
    "Confusion matrix przed redukcją wymiarów:\n",
    "\n",
    "![conf_knn](plots/KNN_confusion.png)\n",
    "\n",
    "\n",
    "Wynik algorytmu na danych testowych z kaggla:\n",
    "\n",
    "![knn_res](plots/KNN_res.png)\n",
    "\n",
    "\n",
    "**Ogólnie model ten poradził sobie raczej słabo**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb648e4a",
   "metadata": {},
   "source": [
    "## Random forest\n",
    "\n",
    "Jednym z najczęściej używanych modeli jest las lasowy. Również postanowiliśmy zaimplementować ten model do rozwiązania tego problemu.\n",
    "\n",
    "\n",
    "Przy użyciu standardowych hiperparametrów wytrenenowaliśmy pierwszy model tego typu, sprawował się on znacznie lepiej niż poprzednie:\n",
    "\n",
    "\n",
    "![roc curve](plots/RF_base_roc.png)\n",
    "\n",
    "Wartość gini dla tego modelu wynosiła około 0.5\n",
    "\n",
    "\n",
    "\n",
    "Przy użyciu podstawowych metod wyszukiwania najlepszych hiperparametrów, takich jak grid oraz random search wytrenowaliśmy model sprawujący się lepiej na danych treningowych\n",
    "\n",
    "\n",
    "![roc curve](plots/RF_random_roc.png)\n",
    "\n",
    "Wartość gini dla tego modelu wynosiła również około 0.5, ale mniej niż w poprzednim przypadku.\n",
    "\n",
    "\n",
    "\n",
    "W ramach tego modelu sprawdziliśmy również feature importance na dwa sposoby - za pomocą wbudowanej funkcji lasu losowego `feature_importance_`, a także za pomocą pakietu `shapely`.\n",
    "\n",
    "Jak się okazało najbardziej istotną kolumną predykcyjną była kolumna oznaczająca brak danych w kolumnie WheelTypeID. W zależności od parametrów, predykcyjność tej kolumny wynosiła nawet do 60%.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e74d1099",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Zdecydowaliśmy się ponownie użyć grid-search'a, aby znaleźć najlepsze hiperparametry modelu XGboost. \\\n",
    "Jak się okazało najlepszy model przy cross-validation=3 sprawdził się XGBoost z następującymi parametrami: \n",
    "\n",
    "{'subsample': 1.0,\n",
    " 'n_estimators': 150,\n",
    " 'max_depth': 5,\n",
    " 'learning_rate': 0.1,\n",
    " 'gamma': 5,\n",
    " 'colsample_bytree': 1.0}\n",
    " \n",
    " Dla modelu z powyższymi parametrami obliczyliśmy różne metryki, które przedstawiają się następująco. \\\n",
    " Dla klasy 0: precision: 0.88, recall: 0.99 \\\n",
    " Dla klasy 1: precision: 0.39, recall: 0.02 \\\n",
    " Accuracy: 0.88\n",
    "\n",
    "A jeżeli chodzi o macierz pomyłek to wygląda ona następująco:\n",
    "\n",
    "![Confusion Matrix](plots/xgb_confusion.png)\n",
    "\n",
    "A krzywe roc tak:\n",
    "\n",
    "Dla danych treningowych:\n",
    "\n",
    "![Roc xgb](plots/roc-xgb-train.png)\n",
    "\n",
    "Gini wynosi tutaj 0.67\n",
    "\n",
    "Dla danych testowych:\n",
    "\n",
    "![Roc xgb test](plots/roc-xgb-test.png)\n",
    "\n",
    "A tutaj wartość gini 0.3\n",
    "\n",
    "Co rzuciło nam się w oczy to fakt, że na danych treningowych wartość gini jest większa niż w przypadku Random Forest. Z drugiej strony, dla danych testowych sytuacja ma się odwrotnie. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58571e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
